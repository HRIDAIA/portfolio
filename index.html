<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Hridai Ambati ‚Äî Portfolio</title>
  <meta name="description" content="Portfolio of Hridai Ambati: projects, resume, and contact." />
  <style>
    :root { --bg:#0b0f14; --card:#111826; --muted:#a5b4c3; --ink:#e6edf3; --accent:#6aa6ff; }
    *{box-sizing:border-box} html,body{margin:0;padding:0;background:var(--bg);color:var(--ink);font-family:system-ui,-apple-system,Segoe UI,Roboto,Inter,Arial,sans-serif}
    a{color:var(--accent);text-decoration:none} a:hover{text-decoration:underline}
    .wrap{max-width:980px;margin:0 auto;padding:32px 20px}
    header{display:flex;gap:20px;align-items:center;margin-top:12px}
    header img{width:120px;height:120px;border-radius:20px;object-fit:cover;box-shadow:0 6px 18px rgba(0,0,0,.35);image-rendering:crisp-edges;image-rendering:-webkit-crisp-edges;image-rendering:pixelated;image-rendering:auto;image-rendering:high-quality;image-rendering:-webkit-optimize-contrast;image-rendering:optimize-contrast;image-rendering:optimize-quality}
    .title h1{margin:0 0 6px;font-size:32px;letter-spacing:.2px}
    .title p{margin:0;color:var(--muted)}
    .chipbar{display:flex;flex-wrap:wrap;gap:8px;margin-top:12px}
    .chip{font-size:12px;padding:6px 10px;border:1px solid #273445;border-radius:999px;color:#cbd5e1}
    .grid{display:grid;grid-template-columns:repeat(12,1fr);gap:16px;margin-top:28px}
    .card{grid-column:span 12;background:var(--card);border:1px solid #223044;border-radius:18px;padding:18px 18px 16px;box-shadow:0 10px 30px rgba(0,0,0,.25)}
    @media(min-width:860px){ .card.half{grid-column:span 6} }
    .card h3{margin:0 0 10px;font-size:18px}
    .card p{margin:0 0 12px;color:var(--muted);line-height:1.5}
    .btnrow{display:flex;gap:10px;flex-wrap:wrap}
    .btn{display:inline-block;padding:10px 14px;border:1px solid #2a3b50;border-radius:10px}
    .tag{font-size:12px;color:#9fb3c7;border:1px solid #2a3b50;padding:4px 8px;border-radius:999px;margin-right:6px}
    footer{margin:36px 0 12px;color:#7d8ea1;font-size:13px}
    .hero{background:linear-gradient(135deg, rgba(106,166,255,.14), rgba(0,0,0,0));border:1px solid #233449;border-radius:18px;padding:22px}
    .hero h2{margin:0 0 10px;font-size:22px}
    .hero p{margin:0;color:var(--muted)}
    .media{display:grid;grid-template-columns:repeat(3,1fr);gap:8px;margin:12px 0}
    .media img{width:100%;height:100%;object-fit:cover;border-radius:10px;border:1px solid #223044}
    .subsections{display:grid;gap:12px;margin-top:10px}
    .subsection{border-top:1px solid #233449;padding-top:12px}
    .subsection img{width:100%;max-width:100%;border-radius:10px;border:1px solid #223044;margin:12px 0;display:block}
    .subsection video{width:100%;max-width:100%;border-radius:10px;border:1px solid #223044;margin:12px 0;display:block;background:#000}
    .video-caption{font-size:13px;color:var(--muted);margin:8px 0 4px;font-style:italic}
    .subsection-images{display:grid;grid-template-columns:1fr;gap:12px;margin:12px 0}
    @media(min-width:600px){ .subsection-images{grid-template-columns:repeat(2,1fr)} }
    @media(min-width:860px){ .subsection-images.three{grid-template-columns:repeat(3,1fr)} }
  </style>
</head>
<body>
  <div class="wrap">
    <header>
      <img src="./assets/images/headshot.png" alt="Hridai Ambati headshot" />
      <div class="title">
        <h1>Hridai Ambati</h1>
        <p>I have a passion for multi-agent autonomy within the realm of aerospace robotics. My work primarily focuses on this area at the Aerospace Robotics Laboratory (ARL), where I contribute to advancing innovative solutions for complex aerospace systems.</p>
        <div class="chipbar">
          <span class="chip">Convex Optimization</span><span class="chip">C++, Python, MATLAB</span><span class="chip">GNC</span><span class="chip">Bayesian State Estimation</span><span class="chip">ROS 2, MuJoCo</span><span class="chip">Multi-Agent Autonomy</span><span class="chip">Cooperative Control</span><span class="chip">Motion Planning</span>
        </div>
      </div>
    </header>

    <section class="grid" aria-label="highlight">
      <div class="card hero">
        <h2>Welcome</h2>
        <p>This site contains my work and experience in research. I am currently looking for roles in <em>GNC, Autonomy, and Systems</em>.</p>
      </div>
    </section>

    <section class="grid" aria-label="resume">
      <div class="card">
        <h3>Resume</h3>
        <p>Download a one-page PDF with selected experience, projects, and skills.</p>
        <div class="btnrow">
          <a class="btn" href="assets/resume/HA%20Resume%20Fall%202025%20np.pdf" target="_blank" rel="noreferrer">Download PDF</a>
          <a class="btn" href="mailto:ahridai00@gmail.com">Email Me</a>
          <a class="btn" href="https://www.linkedin.com/in/ahridai" target="_blank" rel="noreferrer">LinkedIn</a>
        </div>
      </div>
    </section>

    <section class="grid" aria-label="about">
      <div class="card">
        <h3>About</h3>
        <p>My educational and career goals are to enable cooperative space operations through advanced robotics, spacecraft GNC, and high-fidelity simulation. I will design and validate reusable frameworks for formation flight, spacecraft swarms, and on-orbit interaction that utilize perception, planning, and control with rigorous testing. In graduate study, I will improve my knowledge of orbital mechanics, optimal control theory, autonomy, and systems engineering to create open and modular tools for motion planning. These tools will combine dynamic models, modern control theory, and machine learning techniques to develop powerful and efficient behavior that handles safety, uncertainty, and constraints effectively. My end goal is to use spacecraft autonomy that cooperates, self-maintains, and adapts to enable larger missions with extended lifetimes within a more resilient spacecraft infrastructure.</p>
      </div>
    </section>

    <section class="grid" aria-label="featured">
      <div class="card">
        <h3>Featured Project ‚Äî <em>A Multi-Agent Spacecraft Simulation Framework</em></h3>
        <p>The transition from large, monolithic satellites to fleets of smaller spacecraft demonstrates the critical role of validating and evaluating distributed space systems for the future of scientific and commercial missions. This paper presents a high-fidelity simulation framework for the study of formation flight dynamics, development of GNC (guidance, navigation, and control) algorithms, and the simulation of inter-spacecraft interactions. The framework is built on Robot Operating System 2 (ROS 2) and the physics engine MuJoCo. The simulation environment takes place in a relative orbit scenario where dynamics models such as the Hill‚ÄìClohessy‚ÄìWiltshire (HCW) equations can be selected to determine the behavior of all bodies. The simulation supports multiple spacecraft agents with independent sensors, actuators, robotic arms, and GNC systems. State estimation on each spacecraft involves filtering, using a chosen method such as the Extended Kalman Filter (EKF), for sensors such as accelerometers, gyroscopes, and cameras. The GNC systems feature cooperative control algorithms for orbit maneuvers and robotic-arm interactions. Preliminary results demonstrate accurate tracking of desired relative trajectories under disturbances, efficient actuator usage, and scalability to larger formations. The architecture is designed to be extensible and provides a tool to integrate more advanced techniques such as reinforcement learning (RL). By combining multi-agent dynamics, estimation, and control, the framework provides a powerful and adaptive tool for improving performance in real-time spacecraft formation flight.</p>
        <p>
          <span class="tag">ROS 2</span>
          <span class="tag">MuJoCo</span>
          <span class="tag">EKF</span>
          <span class="tag">HCW</span>
        </p>
        <div class="btnrow">
          <a class="btn" href="https://github.com/YOUR-USERNAME/YOUR-REPO" target="_blank" rel="noreferrer">View Code</a>
          <a class="btn" href="#project" rel="noreferrer">Project Details</a>
          <a class="btn" href="#contact">Contact Me</a>
        </div>
        <div class="media" aria-label="project screenshots">
          <img src="assets/images/SIM_robotic_arms.png" alt="Robotic arms simulation screenshot" />
          <img src="assets/images/SIM_foxglove_1.png" alt="Foxglove visualization screenshot" />
          <img src="assets/Screenshot%20from%202025-10-14%2012-39-52.png" alt="Simulation screenshot" />
        </div>
      </div>
    </section>

    <section class="grid" id="project" aria-label="project">
      <div class="card">
        <h3>A Multi-Agent Spacecraft Simulation Framework</h3>
        <div class="subsections">
          <div class="subsection">
            <h4>Overview</h4>
            <p>This high-fidelity simulation framework facilitates the development and testing of formation flight systems. The framework supports multiple dynamics models, guidance, navigation, and control (GNC) algorithms, spacecraft interactions, and state estimation/filtering techniques. Built on ROS 2, the physics simulation is powered by MuJoCo.</p>
            <img src="assets/images/SIM_overview_diagram.png" alt="Framework overview diagram" />
            <p class="video-caption">Sample simulation demonstration of the multi-agent spacecraft framework.</p>
            <video controls src="assets/videos/SampleSimulation.mp4"></video>
          </div>
          <div class="subsection">
            <h4>Framework</h4>
            <p>The framework leverages MuJoCo as its physics engine for its robust capabilities in full 6-DOF rigid body dynamics, realistic joint contact physics, and customizable dynamics models. Additionally, MuJoCo provides comprehensive sensor and actuator models along with high-quality OpenGL visualization, enabling accurate and visually informative simulations. The framework is built on ROS 2, which offers a modular architecture through nodes, topics, and services that facilitate parallel execution and precise simulation timing control. ROS 2's efficient launch and shutdown management capabilities ensure reliable and scalable operation, making it ideal for complex multi-agent spacecraft simulations.</p>
          </div>
          <div class="subsection">
            <h4>Dynamics Modeling</h4>
            <p>The Hill-Clohessy-Wiltshire (HCW) equations provide a fundamental model for describing relative motion between spacecraft in formation flight. The HCW model offers significant advantages, particularly its linear time-invariant dynamics, which enable straightforward analytical solutions and efficient control system design. This linearity simplifies trajectory planning and makes the model computationally efficient for real-time applications. However, the HCW model comes with inherent limitations, most notably its assumption of zero orbital eccentricity. This assumption restricts the model's applicability to circular orbits, making it less suitable for describing relative motion in elliptical orbital scenarios where more sophisticated models such as the Yamanaka-Ankerson or Schweighart-Sedwick equations may be required.</p>
            <img src="assets/images/SIM_dynamics.png" alt="Dynamics modeling diagram" />
            <p class="video-caption">Video demonstration of a stable HCW relative orbit.</p>
            <video controls src="assets/videos/HCWOrbitDemonstration.mp4"></video>
          </div>
          <div class="subsection">
            <h4>State Estimation and Filtering</h4>
            <p>The state estimation system employs a dual-sensor fusion approach to determine spacecraft navigation state. The IMU model, incorporating both accelerometer and gyroscope measurements, provides inertial data that is processed through a filtering algorithm such as an Extended Kalman Filter (EKF) or Unscented Kalman Filter (UKF), ultimately contributing to the navigation state estimation. Additionally, the framework utilizes computer vision for relative state estimation. An RGB camera captures images of the target spacecraft, which are processed through a neural network to determine the distance (magnitude of relative position) between the chaser and target. The vision-based estimates are also filtered and integrated into the navigation state, creating a complementary sensor fusion system. Future development aims to enhance the neural network to recognize different sides of the target spacecraft, enabling full relative position estimation rather than just distance magnitude, which would significantly improve pose awareness and relative navigation capabilities.</p>
            <img src="assets/images/SIM_navigation.png" alt="State estimation and navigation diagram" />
            <p class="video-caption">Multi-camera demonstration of vision-based state estimation.</p>
            <video controls src="assets/videos/MultiCameraDemonsration.mp4"></video>
          </div>
          <div class="subsection">
            <h4>Guidance and Control</h4>
            <p>The guidance and control system implements separate but coordinated controllers for position and pointing (attitude) control. Position control manages the spacecraft's translational motion, tracking desired relative positions while incorporating collision avoidance to maintain safe separation distances from other spacecraft in the formation. Pointing control, on the other hand, manages the spacecraft's rotational motion to achieve and maintain desired orientations.</p>
            <p>Both position and pointing control can be implemented using either PID controllers or Model Predictive Control (MPC). The MPC formulation solves an optimization problem over a finite prediction horizon, minimizing a cost function that penalizes tracking errors and control effort while satisfying constraints on states and control inputs. For position control, the MPC problem can often be formulated as a quadratic program (QP) due to the linear dynamics of relative motion, enabling fast real-time solutions. However, pointing control presents additional complexity: attitude dynamics are inherently nonlinear due to the non-commutative nature of rotations. This nonlinearity requires the pointing control MPC to be formulated as a nonlinear optimization problem, necessitating Sequential Quadratic Programming (SQP) methods for solution. SQP iteratively approximates the nonlinear problem as a series of quadratic subproblems, handling the nonlinear constraints and dynamics associated with quaternion-based attitude representation and rotational motion.</p>
            <img src="assets/images/SIM_GNC_overview.png" alt="GNC overview diagram" />
            <p class="video-caption">Demonstration of guidance and control algorithms in action.</p>
            <video controls src="assets/videos/GuidanceDemonstration.mp4"></video>
            <img src="assets/images/SIM_PID_overview.png" alt="PID control overview" />
            <img src="assets/images/SIM_MPC_overview.png" alt="MPC control overview" />
          </div>
          <div class="subsection">
            <h4>Actuators</h4>
            <p>Each spacecraft is equipped with 12 reaction control system (RCS) thrusters and 4 reaction wheels, providing redundant actuation for both translational and rotational control. This redundancy creates an overactuated system where the number of actuators exceeds the number of controlled degrees of freedom, resulting in infinitely many solutions that can achieve the desired force and torque commands. The actuator allocation problem addresses this redundancy by solving an optimization problem that selects the optimal control inputs.</p>
            <p>The allocation algorithm minimizes the L1 norm of the control input vector, which promotes actuator efficiency by encouraging sparse solutions that utilize fewer actuators. The optimization problem is subject to equality constraints ensuring that the generated wrench (combined force and torque) from the actuators matches the commanded wrench, as well as inequality constraints that enforce actuator limits (e.g., maximum thruster force and reaction wheel torque). By solving this constrained optimization problem, the allocation function determines the most efficient combination of thruster firings and reaction wheel torques to achieve the desired control objectives while respecting physical limitations and minimizing overall control effort.</p>
            <img src="assets/images/SIM_actuator_allocation.png" alt="Actuator allocation diagram" />
          </div>
          <div class="subsection">
            <h4>Simulating Interactions</h4>
            <p>The framework supports spacecraft interactions through robotic manipulators, enabling complex on-orbit operations such as repositioning target spacecraft, performing maintenance tasks, or manipulating objects. These interactions present significant control challenges due to the complex dynamics of contact physics, multi-body kinematics, and the need to maintain stability while applying forces and torques during contact operations.</p>
            <p>To address these challenges, the framework plans to implement advanced control strategies for robotic arm operations. Two primary approaches are under consideration: reinforcement learning (RL) and convex optimization. The RL approach would leverage machine learning to develop control policies that can adapt to varying contact conditions and learn optimal manipulation strategies through simulation experience. Alternatively, the convex optimization approach would involve convexifying the contact physics problem, transforming the non-convex contact mechanics into a convex optimization problem that can be solved efficiently while ensuring feasibility and optimality of the manipulation trajectories. Both approaches aim to enable robust and efficient control of robotic arms for autonomous on-orbit servicing and assembly operations.</p>
            <img src="assets/images/SIM_interactions_overview.png" alt="Interactions overview diagram" />
            <img src="assets/images/SIM_arm_interaction.png" alt="Robotic arm interaction" />
          </div>
          <div class="subsection">
            <h4>Validation</h4>
            <p>Validation of the simulation framework is conducted using Foxglove, a powerful visualization and debugging tool that integrates seamlessly with ROS 2 through its native bridge. This integration enables real-time monitoring and analysis of every ROS 2 node within the simulation. All published topics, including sensor data, navigation states, control commands, and custom messages, are viewable and plottable directly within Foxglove. This capability is essential for debugging complex multi-agent interactions, verifying algorithm performance, and ensuring the fidelity of the physics simulation. By visualizing data streams in real-time, users can quickly identify anomalies, track system behavior, and validate the effectiveness of GNC algorithms and state estimation filters against expected performance metrics.</p>
            <img src="assets/images/SIM_foxglove_1.png" alt="Foxglove visualization of ROS 2 data streams" />
          </div>
          <div class="subsection">
            <h4>Scalability</h4>
            <p>The framework is designed to scale effectively to support increasingly complex formation flight scenarios. A key scalability feature is the direct correspondence between agent count and node count in the ROS 2 architecture, where each spacecraft agent runs as an independent node with its own namespace, enabling parallel execution and modular expansion. The framework supports scalable camera simulation, allowing multiple spacecraft to carry vision sensors simultaneously and process their data independently. Complex control logic can be distributed across nodes, with each agent maintaining its own guidance, navigation, and control algorithms. The system is also designed to handle multiple robotic arms per spacecraft, with independent control and physics simulation for each manipulator. Additionally, optical navigation capabilities can be scaled across the formation, enabling relative positioning and formation-keeping through vision-based algorithms distributed across multiple agents. This modular, node-based architecture ensures that computational resources can be efficiently distributed and that the framework remains performant even as formation size and complexity increase.</p>
          </div>
          <div class="subsection">
            <h4>Future Work</h4>
            <p>Future development will focus on several key areas to expand the framework's capabilities and realism. Additional dynamics models, such as the Yamanaka-Ankerson and Schweighart-Sedwick equations, will be integrated to support elliptical orbit scenarios and provide more accurate relative motion descriptions. Nonlinear GNC algorithms will be implemented to handle more complex mission profiles and improve performance in highly dynamic environments. Learned perception systems will leverage machine learning to enhance neural network-based vision capabilities, enabling more robust target recognition and relative pose estimation. Large-scale validation efforts will test the framework's performance with extensive formation flight scenarios involving dozens of spacecraft. Vision-based filters will be developed to better integrate camera measurements with other sensor modalities, improving state estimation accuracy and robustness. Finally, robotic arm interactions will be fully implemented with control algorithms for autonomous manipulation tasks, including the RL and convex optimization approaches discussed earlier, enabling complex on-orbit servicing and assembly operations.</p>
          </div>
        </div>
      </div>
    </section>

    

    <section class="grid" id="contact" aria-label="contact">
      <div class="card">
        <h3>Contact</h3>
        <p>üìß <a href="mailto:ahridai00@gmail.com">Email</a> &nbsp; ¬∑ &nbsp; üíº <a href="https://www.linkedin.com/in/ahridai">LinkedIn</a> &nbsp; ¬∑ &nbsp; üêô <a href="https://github.com/HRIDAIA/">GitHub</a></p>
      </div>
    </section>

    <footer>¬© <span id="y"></span> Hridai Ambati</footer>
  </div>
  <script>document.getElementById('y').textContent = new Date().getFullYear()</script>
</body>
</html>
