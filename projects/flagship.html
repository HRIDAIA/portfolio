<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Flagship Project ‚Äî Multi-Agent Spacecraft Simulation Framework</title>
  <meta name="description" content="Detailed case study of a multi-agent spacecraft simulation framework built with ROS 2 and MuJoCo." />
  <link rel="icon" href="../assets/images/headshot.png" type="image/png" />
  <style>
    :root { --bg:#0b0f14; --card:#111826; --muted:#a5b4c3; --ink:#e6edf3; --accent:#6aa6ff; }
    *{box-sizing:border-box} html,body{margin:0;padding:0;background:var(--bg);color:var(--ink);font-family:system-ui,-apple-system,Segoe UI,Roboto,Inter,Arial,sans-serif}
    a{color:var(--accent);text-decoration:none} a:hover{text-decoration:underline}
    .wrap{max-width:1400px;margin:0 auto;padding:32px 20px}
    .project-header{margin-bottom:28px}
    .project-header h1{margin:12px 0 10px;font-size:32px;letter-spacing:.2px}
    .project-header p{margin:0;color:var(--muted);line-height:1.6}
    .back-link{display:inline-flex;align-items:center;font-size:14px;color:var(--muted)}
    .back-link span{margin-right:6px}
    .highlight-list{margin:16px 0 0;padding-left:20px;color:var(--muted);line-height:1.6}
    .highlight-list li{margin:6px 0}
    .project-nav{display:flex;flex-wrap:wrap;gap:10px;margin-top:18px}
    .project-nav a{padding:8px 12px;border:1px solid #273445;border-radius:999px;font-size:13px;color:#cbd5e1}
    .project-nav a:hover{background:rgba(106,166,255,.08)}
    .grid{display:grid;grid-template-columns:repeat(12,1fr);gap:16px;margin-top:28px}
    .card{grid-column:span 12;background:var(--card);border:1px solid #223044;border-radius:18px;padding:18px 18px 16px;box-shadow:0 10px 30px rgba(0,0,0,.25)}
    .card h3{margin:0 0 10px;font-size:20px}
    .card p{margin:0 0 12px;color:var(--muted);line-height:1.6}
    .subsections{display:grid;gap:12px;margin-top:10px}
    .subsection{border-top:1px solid #233449;padding-top:12px}
    .subsection:first-child{border-top:none;padding-top:0}
    .subsection h4{margin:0 0 8px;font-size:18px}
    .subsection ul{margin:12px 0;padding-left:20px;color:var(--muted);line-height:1.6}
    .subsection ul li{margin:6px 0}
    .subsection img{width:100%;max-width:100%;border-radius:10px;border:1px solid #223044;margin:12px 0;display:block}
    .subsection video{width:100%;max-width:100%;border-radius:10px;border:1px solid #223044;margin:12px 0;display:block;background:#000}
    .image-caption{font-size:15px;color:var(--muted);margin:4px 0 8px;font-style:italic}
    .video-caption{font-size:15px;color:var(--muted);margin:8px 0 4px;font-style:italic}
    .overview-media{display:grid;grid-template-columns:1fr;gap:12px;margin:12px 0}
    @media(min-width:800px){ .overview-media{grid-template-columns:repeat(2,1fr)} }
    .overview-media-item{display:flex;flex-direction:column}
    .overview-media-item img,.overview-media-item video{width:100%;max-width:100%;border-radius:10px;border:1px solid #223044;margin:0}
    .subsection-media{display:grid;grid-template-columns:1fr;gap:12px;margin:12px 0}
    @media(min-width:800px){ .subsection-media{grid-template-columns:repeat(2,1fr)} }
    .subsection-media-item{display:flex;flex-direction:column}
    .subsection-media-item img,.subsection-media-item video{width:100%;max-width:100%;border-radius:10px;border:1px solid #223044;margin:0}
    .gnc-image-video{display:grid;grid-template-columns:1fr;gap:12px;margin:12px 0}
    @media(min-width:800px){ .gnc-image-video{grid-template-columns:1fr 1fr;align-items:start} }
    .gnc-image-video .subsection-media-item{display:flex;flex-direction:column}
    .gnc-image-video .subsection-media-item video{width:100%;height:auto;border-radius:10px;border:1px solid #223044;margin:0}
    .gnc-image-video .subsection-media-item img{width:auto;max-width:100%;height:auto;object-fit:contain;border-radius:10px;border:1px solid #223044;margin:0}
    .two-images{display:grid;grid-template-columns:1fr;gap:12px;margin:12px 0}
    @media(min-width:800px){ .two-images{grid-template-columns:repeat(2,1fr)} }
    .two-images-item{display:flex;flex-direction:column}
    .two-images-item img{width:100%;max-width:100%;border-radius:10px;border:1px solid #223044;margin:0}
    footer{margin:36px 0 12px;color:#7d8ea1;font-size:13px;text-align:center}
  </style>
</head>
<body>
  <div class="wrap">
    <header class="project-header">
      <a class="back-link" href="../index.html"><span>‚Üê</span>Back to Portfolio</a>
      <h1>Multi-Agent Spacecraft Simulation Framework</h1>
      <p>High-fidelity formation flight simulations built on ROS 2 and MuJoCo. Independent agents coordinate sensing, estimation, guidance, and control to evaluate distributed spacecraft autonomy.</p>
      <ul class="highlight-list">
        <li>Extensible ROS 2 architecture with per-spacecraft namespaces and synchronized simulation time.</li>
        <li>Interchangeable relative motion dynamics (HCW and beyond) for mission-specific fidelity.</li>
        <li>Integrated pipelines for state estimation, guidance planning, control execution, and actuation.</li>
      </ul>
      <nav class="project-nav">
        <a href="#overview">Overview</a>
        <a href="#framework">Framework</a>
        <a href="#dynamics">Dynamics</a>
        <a href="#state-estimation">State Estimation</a>
        <a href="#guidance">Guidance</a>
        <a href="#control">Control</a>
        <a href="#actuators">Actuators</a>
        <a href="#interactions">Interactions</a>
        <a href="#validation">Validation</a>
        <a href="#scalability">Scalability</a>
        <a href="#future-work">Future Work</a>
      </nav>
    </header>

    <section class="grid" aria-label="project-details">
      <div class="card">
        <h3>Project Details</h3>
        <div class="subsections">
          <article class="subsection" id="overview">
            <h4>Overview</h4>
            <p>This high-fidelity simulation framework facilitates the development and testing of formation flight systems. The framework supports multiple dynamics models, guidance, navigation, and control (GNC) algorithms, spacecraft interactions, and state estimation/filtering techniques. Built on ROS 2, the physics simulation is powered by MuJoCo.</p>
            <div class="overview-media">
              <div class="overview-media-item">
                <p class="image-caption">Architecture overview highlighting ROS 2 node/topic groups and the MuJoCo simulation stack.</p>
                <div class="two-images">
                  <div class="two-images-item">
                    <p class="image-caption">ROS 2 overview: topic messages, node groups, and namespaces.</p>
                    <img src="../assets/images/ROS2_overview.PNG" alt="ROS 2 architecture overview diagram" />
                  </div>
                  <div class="two-images-item">
                    <p class="image-caption">MuJoCo overview: simulation core with sensors, actuators, and visualization.</p>
                    <img src="../assets/images/Mujoco_overview.PNG" alt="MuJoCo simulation overview diagram" />
                  </div>
                </div>
              </div>
              <div class="overview-media-item">
                <p class="video-caption">Sample simulation demonstration of the multi-agent spacecraft framework.</p>
                <video controls src="../assets/videos/SampleSimulation.mp4"></video>
              </div>
            </div>
          </article>

          <article class="subsection" id="framework">
            <h4>Framework</h4>
            <p>The framework uses MuJoCo as its physics engine for its capabilities in full 6-DOF rigid body dynamics, realistic joint contact physics, and customizable dynamics models. MuJoCo also provides sensor and actuator models along with OpenGL visualization, enabling accurate and visually informative simulations. The framework is built on ROS 2, which offers a modular architecture through nodes, topics, and services that facilitate parallel execution and precise simulation timing control. ROS 2's efficient launch and shutdown management capabilities ensure reliable and scalable operation, making it ideal for complex multi-agent spacecraft simulations.</p>
          </article>

          <article class="subsection" id="dynamics">
            <h4>Dynamics Modeling</h4>
            <p>The Hill-Clohessy-Wiltshire (HCW) equations provide a fundamental model for describing relative motion between spacecraft in formation flight. The HCW model offers significant advantages, particularly its linear time-invariant dynamics, which produce straightforward analytical solutions and efficient control system design. This linearity simplifies trajectory planning and makes the model computationally efficient for real-time applications.</p>
            <p>The HCW model comes with inherent limitations, most notably its assumption of zero orbital eccentricity. This assumption restricts the model's applicability to circular orbits, making it less suitable for describing relative motion in elliptical orbital scenarios where more sophisticated models such as the Yamanaka-Ankerson or Schweighart-Sedwick equations may be required.</p>
            <p class="image-caption">Hill-Clohessy-Wiltshire (HCW) equations and alternative dynamics models for relative orbit motion.</p>
            <img src="../assets/images/SIM_dynamics.png" alt="Dynamics modeling diagram" />
            <p class="video-caption">Video demonstration of a stable HCW relative orbit.</p>
            <video controls src="../assets/videos/HCWOrbitDemonstration.mp4"></video>
          </article>

          <article class="subsection" id="state-estimation">
            <h4>State Estimation & Navigation</h4>
            <p>The state estimation system employs a dual-sensor fusion approach to determine spacecraft navigation state. The IMU model, incorporating both accelerometer and gyroscope measurements, provides inertial data that is processed through a filtering algorithm such as an Extended Kalman Filter (EKF) or Unscented Kalman Filter (UKF), ultimately contributing to the navigation state estimation.</p>
            <p>Additionally, the framework utilizes computer vision for relative state estimation. An RGB camera captures images of the target spacecraft, which are processed through a neural network to determine the distance (magnitude of relative position) between the chaser and target. The vision-based estimates are also filtered and integrated into the navigation state, creating a complementary sensor fusion system. Future development aims to enhance the neural network to recognize different sides of the target spacecraft, enabling full relative position estimation rather than just distance magnitude, which would significantly improve pose awareness and relative navigation capabilities.</p>
            <div class="subsection-media">
              <div class="subsection-media-item">
                <p class="image-caption">State estimation pipeline showing IMU processing, neural network vision processing, and filter integration.</p>
                <img src="../assets/images/SIM_navigation.png" alt="State estimation and navigation diagram" />
              </div>
              <div class="subsection-media-item">
                <p class="video-caption">Multi-camera demonstration of vision-based state estimation.</p>
                <video controls src="../assets/videos/MultiCameraDemonsration.mp4"></video>
              </div>
            </div>
          </article>

          <article class="subsection" id="guidance">
            <h4>Guidance</h4>
            <p>The guidance stack generates reference trajectories that respect mission objectives and collision-avoidance rules for every spacecraft in the formation. Desired relative orbits are expressed as time-varying setpoints derived from HCW solutions, rendezvous waypoints, or operator-specified inspection paths. Each agent evaluates feasible approach corridors, constraining separation distances, line-of-sight cones, and plume impingement limits before publishing guidance commands over ROS 2 topics.</p>
            <p>Scenario-specific planners support impulsive burns for rapid retargeting as well as continuous-thrust profiles for fine station keeping. Guidance outputs are timestamped and synchronized across agents to maintain coherent formations, enabling cooperative maneuvers such as reconfiguration, leader‚Äìfollower swaps, and coordinated inspection arcs.</p>
          </article>

          <article class="subsection" id="control">
            <h4>Control</h4>
            <p>The control system implements separate but coordinated controllers for position and pointing (attitude) regulation. Position control manages translational motion, tracking the guidance stack‚Äôs relative position commands while incorporating collision avoidance to maintain safe separation distances from neighboring spacecraft. Pointing control manages rotational motion so that sensors, manipulators, and communications hardware maintain required orientations.</p>
            <p>Both position and pointing control can be implemented using either PID controllers or Model Predictive Control (MPC). The MPC formulation solves an optimization problem over a finite prediction horizon, minimizing a cost function that penalizes tracking errors and control effort while satisfying constraints on states and control inputs. For position control, the MPC problem can often be formulated as a quadratic program (QP) due to the linear dynamics of relative motion, enabling fast real-time solutions. Pointing control presents additional complexity: attitude dynamics are inherently nonlinear due to the non-commutative nature of rotations. This nonlinearity requires the pointing control MPC to be formulated as a nonlinear optimization problem, necessitating Sequential Quadratic Programming (SQP) methods for solution. SQP iteratively approximates the nonlinear problem as a series of quadratic subproblems, handling the nonlinear constraints and dynamics associated with quaternion-based attitude representation and rotational motion.</p>
            <div class="gnc-image-video">
              <div class="subsection-media-item">
                <p class="image-caption">Guidance, navigation, and control system architecture with position and pointing control loops.</p>
                <img src="../assets/images/SIM_GNC_overview.png" alt="GNC overview diagram" />
              </div>
              <div class="subsection-media-item">
                <p class="video-caption">Demonstration of guidance and control algorithms in action.</p>
                <video controls src="../assets/videos/GuidanceDemonstration.mp4"></video>
              </div>
            </div>
            <div class="two-images">
              <div class="two-images-item">
                <p class="image-caption">PID controller architecture with collision avoidance for position and orientation control.</p>
                <img src="../assets/images/SIM_PID_overview.png" alt="PID control overview" />
              </div>
              <div class="two-images-item">
                <p class="image-caption">Model Predictive Control (MPC) formulation with dynamics constraints and cost function minimization.</p>
                <img src="../assets/images/SIM_MPC_overview.png" alt="MPC control overview" />
              </div>
            </div>
          </article>

          <article class="subsection" id="actuators">
            <h4>Actuators</h4>
            <div class="subsection-text-image">
              <div class="subsection-text-content">
                <ul>
                  <li><strong>Actuator configuration:</strong> Each spacecraft is equipped with 12 reaction control system (RCS) thrusters and 4 reaction wheels, providing redundant actuation for both translational and rotational control.</li>
                  <li><strong>Overactuated system:</strong> This redundancy creates an overactuated system where the number of actuators exceeds the number of controlled degrees of freedom, resulting in infinitely many solutions that can achieve the desired force and torque commands.</li>
                  <li><strong>Actuator allocation problem:</strong> The actuator allocation problem addresses this redundancy by solving an optimization problem that selects the optimal control inputs.</li>
                  <li><strong>L1 norm minimization:</strong> The allocation algorithm minimizes the L1 norm of the control input vector, which promotes actuator efficiency by encouraging sparse solutions that utilize fewer actuators.</li>
                  <li><strong>Optimization constraints:</strong> The optimization problem is subject to equality constraints ensuring that the generated wrench (combined force and torque) from the actuators matches the commanded wrench, as well as inequality constraints that enforce actuator limits (e.g., maximum thruster force and reaction wheel torque).</li>
                  <li><strong>Optimal solution:</strong> By solving this constrained optimization problem, the allocation function determines the most efficient combination of thruster firings and reaction wheel torques to achieve the desired control objectives while respecting physical limitations and minimizing overall control effort.</li>
                </ul>
              </div>
              <div class="subsection-image-wrapper">
                <p class="image-caption">Actuator allocation optimization problem minimizing L1 norm with wrench equality and actuator limit constraints.</p>
                <img src="../assets/images/SIM_actuator_allocation.png" alt="Actuator allocation diagram" />
              </div>
            </div>
          </article>

          <article class="subsection" id="interactions">
            <h4>Simulating Interactions</h4>
            <ul>
              <li><strong>Robotic manipulator support:</strong> The framework supports spacecraft interactions through robotic manipulators, enabling complex on-orbit operations such as repositioning target spacecraft, performing maintenance tasks, or manipulating objects.</li>
              <li><strong>Control challenges:</strong> These interactions present significant control challenges due to the complex dynamics of contact physics, multi-body kinematics, and the need to maintain stability while applying forces and torques during contact operations.</li>
              <li><strong>Reinforcement learning approach:</strong> The RL approach would leverage machine learning to develop control policies that can adapt to varying contact conditions and learn optimal manipulation strategies through simulation experience.</li>
              <li><strong>Convex optimization approach:</strong> The convex optimization approach would involve convexifying the contact physics problem, transforming the non-convex contact mechanics into a convex optimization problem that can be solved efficiently while ensuring feasibility and optimality of the manipulation trajectories.</li>
              <li><strong>Unified goal:</strong> Both approaches aim to enable efficient control of robotic arms for autonomous on-orbit servicing and assembly operations.</li>
            </ul>
            <div class="two-images">
              <div class="two-images-item">
                <p class="image-caption">Robotic arm interaction simulation with UR10e manipulators performing contact operations.</p>
                <img src="../assets/images/SIM_arm_interaction.png" alt="Robotic arm interaction" />
              </div>
              <div class="two-images-item">
                <p class="image-caption">Overview of spacecraft interaction capabilities and robotic arm control architecture.</p>
                <img src="../assets/images/SIM_interactions_overview.png" alt="Interactions overview diagram" />
              </div>
            </div>
          </article>

          <article class="subsection" id="validation">
            <h4>Validation</h4>
            <div class="subsection-text-image">
              <div class="subsection-text-content">
                <ul>
                  <li><strong>Foxglove integration:</strong> Validation of the simulation framework is conducted using Foxglove, a powerful visualization and debugging tool that integrates seamlessly with ROS 2 through its native bridge.</li>
                  <li><strong>Real-time monitoring:</strong> The integration enables real-time monitoring and analysis of every ROS 2 node within the simulation, allowing users to visualize data streams as they occur.</li>
                  <li><strong>Comprehensive data visualization:</strong> All published topics, including sensor data, navigation states, control commands, and custom messages, are viewable and plottable directly within Foxglove.</li>
                  <li><strong>Multi-agent debugging:</strong> This capability is essential for debugging complex multi-agent interactions, verifying algorithm performance, and ensuring the fidelity of the physics simulation.</li>
                  <li><strong>Performance validation:</strong> By visualizing data streams in real-time, users can quickly identify anomalies, track system behavior, and validate the effectiveness of GNC algorithms and state estimation filters against expected performance metrics.</li>
                </ul>
              </div>
              <div class="subsection-image-wrapper">
                <p class="image-caption">Foxglove interface showing real-time ROS 2 navigation state plots for validation and debugging.</p>
                <img src="../assets/images/SIM_foxglove_1.png" alt="Foxglove visualization of ROS 2 data streams" />
              </div>
            </div>
          </article>

          <article class="subsection" id="scalability">
            <h4>Scalability</h4>
            <ul>
              <li><strong>Direct agent-to-node correspondence:</strong> Each spacecraft agent runs as an independent ROS 2 node with its own namespace, enabling parallel execution and modular expansion.</li>
              <li><strong>Scalable camera simulation:</strong> Multiple spacecraft can carry vision sensors simultaneously and process their data independently.</li>
              <li><strong>Distributed control logic:</strong> Complex guidance, navigation, and control algorithms can be distributed across nodes, with each agent maintaining its own GNC systems.</li>
              <li><strong>Multi-arm support:</strong> The system handles multiple robotic arms per spacecraft, with independent control and physics simulation for each manipulator.</li>
              <li><strong>Optical navigation scaling:</strong> Vision-based algorithms can be distributed across multiple agents, enabling relative positioning and formation-keeping capabilities across the entire formation.</li>
              <li><strong>Efficient resource distribution:</strong> The modular, node-based architecture ensures computational resources are efficiently distributed, maintaining performance even as formation size and complexity increase.</li>
            </ul>
          </article>

          <article class="subsection" id="future-work">
            <h4>Future Work</h4>
            <ul>
              <li><strong>Additional dynamics models:</strong> Integration of Yamanaka-Ankerson and Schweighart-Sedwick equations to support elliptical orbit scenarios and provide more accurate relative motion descriptions.</li>
              <li><strong>Nonlinear GNC algorithms:</strong> Implementation of nonlinear guidance, navigation, and control algorithms to handle more complex mission profiles and improve performance in highly dynamic environments.</li>
              <li><strong>Learned perception systems:</strong> Development of machine learning-enhanced neural network vision capabilities for more robust target recognition and relative pose estimation.</li>
              <li><strong>Large-scale validation:</strong> Testing framework performance with extensive formation flight scenarios involving dozens of spacecraft.</li>
              <li><strong>Vision-based filters:</strong> Development of filters to better integrate camera measurements with other sensor modalities, improving state estimation accuracy and robustness.</li>
              <li><strong>Robotic arm interactions:</strong> Full implementation of control algorithms for autonomous manipulation tasks, including reinforcement learning and convex optimization approaches, enabling complex on-orbit servicing and assembly operations.</li>
            </ul>
          </article>
        </div>
      </div>
    </section>

    <section class="grid" aria-label="contact">
      <div class="card">
        <h3>Contact</h3>
        <p>üìß <a href="mailto:ahridai00@gmail.com">Email</a> &nbsp; ¬∑ &nbsp; üíº <a href="https://www.linkedin.com/in/ahridai" target="_blank" rel="noreferrer">LinkedIn</a> &nbsp; ¬∑ &nbsp; üêô <a href="https://github.com/HRIDAIA/" target="_blank" rel="noreferrer">GitHub</a></p>
      </div>
    </section>

    <footer>¬© <span id="y"></span> Hridai Ambati</footer>
  </div>
  <script>
    document.getElementById('y').textContent = new Date().getFullYear();
    // Match GNC image height to video height
    function matchGNCImageHeight() {
      const gncContainer = document.querySelector('.gnc-image-video');
      if (!gncContainer) return;
      const video = gncContainer.querySelector('video');
      const img = gncContainer.querySelector('img');
      if (video && img) {
        const updateHeight = () => {
          const videoHeight = video.offsetHeight;
          if (videoHeight > 0) {
            img.style.height = videoHeight + 'px';
            img.style.width = 'auto';
          }
        };
        video.addEventListener('loadedmetadata', updateHeight);
        video.addEventListener('loadeddata', updateHeight);
        setTimeout(updateHeight, 100);
        window.addEventListener('resize', updateHeight);
      }
    }
    matchGNCImageHeight();
  </script>
</body>
</html>

